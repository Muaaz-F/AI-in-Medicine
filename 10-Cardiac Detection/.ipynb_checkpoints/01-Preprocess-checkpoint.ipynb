{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "external-warren",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook we will preprocess the data for the cardiac detection task.\n",
    "We provide bounding boxes for around 500 images of the RSNA pneumonia detection challenge dataset which you have already downloaded in the last section. \n",
    "\n",
    "We will again convert the images to npy files for efficient storage and faster data loading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-expansion",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "* pathlib for easy path handling\n",
    "* pydicom for reading dicom files\n",
    "* numpy for storing the actual images\n",
    "* cv2 for directly resizing the images\n",
    "* pandas to read the provided labels\n",
    "* matplotlib for visualization\n",
    "* patches from matplotlib to draw bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "binding-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-mambo",
   "metadata": {},
   "source": [
    "At first, we read the csv file containing the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "asian-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"./rsna_heart_detection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "historic-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = Path(\"C:/Users/sohra/Desktop/Test/rsna-pneumonia-detection-challenge/stage_2_train_images/\")\n",
    "SAVE_PATH = Path(\"C:/Users/sohra/Desktop/Test/Processed-Heart-Detection/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-selection",
   "metadata": {},
   "source": [
    "Let's visualize some images with corresponding bounding boxes around the heart\n",
    "<br> use `break` to better understand the for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(2, 2)\n",
    "c = 0\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        data = labels.iloc[c]\n",
    "        # It creates the intended image path to be read\n",
    "        patient_id = data[\"name\"]\n",
    "        dcm_path = ROOT_PATH/str(patient_id)\n",
    "        dcm_path = dcm_path.with_suffix(\".dcm\")\n",
    "\n",
    "        # Now, we are first reading it and then extracting the 2D array of image date\n",
    "        dcm = pydicom.read_file(dcm_path)\n",
    "        dcm_array = dcm.pixel_array\n",
    "        dcm_array = cv2.resize(dcm_array, (224, 224))\n",
    "\n",
    "        # We cannot use labels[c] - you can test it\n",
    "        data = labels.iloc[c]\n",
    "        x = data[\"x0\"]\n",
    "        y = data[\"y0\"]\n",
    "        width = data[\"w\"]\n",
    "        height = data[\"h\"]\n",
    "        \n",
    "        axis[i][j].imshow(dcm_array, cmap=\"bone\")\n",
    "        rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor=\"r\", facecolor='none')\n",
    "        axis[i][j].add_patch(rect)\n",
    "        c+=1\n",
    "\n",
    "plt.tight_layout()\n",
    "        \n",
    "#You can put your test code here\n",
    "#print(labels.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-chancellor",
   "metadata": {},
   "source": [
    "We use a similar preprocessing routine to the one used for the classification task.<br />\n",
    "To be able to distinguish between train and validation subjects, we store them in two lists and later save these lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c2298a-6093-4c19-b400-22f6b6c992a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can also try labels.h or labels.name\n",
    "list(labels.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235d395-71e7-437a-9ca4-603f4cdb113c",
   "metadata": {},
   "source": [
    "***Side Note***, For `assert`, see this: https://www.w3schools.com/python/ref_keyword_assert.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12672975-203a-4aa9-b43d-6c528577e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"hello\"\n",
    "\n",
    "#if condition returns True, then nothing happens:\n",
    "assert x == \"hello\"\n",
    "\n",
    "#if condition returns False, AssertionError is raised:\n",
    "assert x == \"goodbye\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d116c4-876e-4fe1-9f34-89942e621ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x != \"hello\", \"x should be 'hello'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "comprehensive-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = 0\n",
    "sums_squared = 0\n",
    "train_ids = []\n",
    "val_ids = []\n",
    "\n",
    "for counter, patient_id in enumerate(list(labels.name)):  \n",
    "    dcm_path = ROOT_PATH/patient_id  # Create the path to the dcm file\n",
    "    dcm_path = dcm_path.with_suffix(\".dcm\")  # And add the .dcm suffix\n",
    "    \n",
    "    dcm = pydicom.read_file(dcm_path)  # Read the dicom file with pydicom\n",
    "    \n",
    "     # Retrieve the actual image \n",
    "    dcm_array = dcm.pixel_array\n",
    "    assert dcm_array.shape == (1024, 1024)\n",
    "    \n",
    "    # Resize the image to drastically improve training speed\n",
    "    # In order to reduce the space when storing the image we convert it to float16\n",
    "    # Standardize to 0-1 range\n",
    "    dcm_array = (cv2.resize(dcm_array, (224, 224)) / 255).astype(np.float16)\n",
    "            \n",
    "    # 4/5 train split, 1/5 val split\n",
    "    train_or_val = \"train\" if counter < 400 else \"val\" \n",
    "    \n",
    "    # Add to corresponding train or validation patient index list\n",
    "    if train_or_val == \"train\":\n",
    "        train_ids.append(patient_id)\n",
    "    else:\n",
    "        val_ids.append(patient_id)\n",
    "    \n",
    "    current_save_path = SAVE_PATH/train_or_val # Define save path and create if necessary\n",
    "    current_save_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    np.save(current_save_path/patient_id, dcm_array)  # Save the array in the corresponding directory\n",
    "    \n",
    "    normalizer = dcm_array.shape[0] * dcm_array.shape[1]  # Normalize sum of image\n",
    "    if train_or_val == \"train\":  # Only use train data to compute dataset statistics\n",
    "        sums += np.sum(dcm_array) / normalizer\n",
    "        sums_squared += (np.power(dcm_array, 2).sum()) / normalizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5511f4e4-0309-435d-a934-b8ba3a5253d6",
   "metadata": {},
   "source": [
    "Add an `IF STATEMENT` with `break` at the end of the code to break the code at 5th loop because we want to assess some parameters within that specific loop\n",
    "\n",
    "Remember that you need to get rid of `break` if you want to go through all the loops later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-income",
   "metadata": {},
   "source": [
    "Finally we store the train and val subject ids\n",
    "<br> for more information about `np.save` refer to https://numpy.org/doc/stable/reference/generated/numpy.save.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "239db10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_det_path = Path('train_subjects_det')\n",
    "val_det_path = Path('train_subjects_det')\n",
    "\n",
    "# Create the folder\n",
    "train_det_path.mkdir(parents=True, exist_ok=True)\n",
    "val_det_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "institutional-attraction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save(\"train_subjects_det\", train_ids)\n",
    "np.save(\"val_subjects_det\", val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "virtual-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = sums / len(train_ids)\n",
    "std = np.sqrt(sums_squared / len(train_ids) - (mean**2), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean of Dataset: {mean}, STD: {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512bfd3-eed2-4a3f-92c8-33daeaca9a28",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
